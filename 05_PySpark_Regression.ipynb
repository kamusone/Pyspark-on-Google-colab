{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05.PySpark_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamusone/Pyspark-on-Google-colab/blob/master/05_PySpark_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1NmrPZHjkhu",
        "colab_type": "text"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "## PySpark Regression on Colab \n",
        "\n",
        "### Author: Wenqiang Feng\n",
        "### Date: 1/10/2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq1wDXlhj5so",
        "colab_type": "text"
      },
      "source": [
        "In data mining, Regression is a model to represent the relationship between the value of lable ( or target, it is numerical variable) and on one or more features (or predictors they can be numerical and categorical variables)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OifyEyI4qojG",
        "colab_type": "text"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2lH68Of22bm",
        "colab_type": "text"
      },
      "source": [
        "### **1.Java -version**\n",
        "**Caution:** Spark has some incompatibility **issues** with Java 11. If you get ``IllegalArgumentException: 'Unsupported class file major version 55'`` error message, you need downgrade the Java 11 to 8 and restarting the runtime. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yBPkYy-edFd",
        "colab_type": "text"
      },
      "source": [
        "#### 1.1 Check Java version "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W6RizKlwiVa",
        "colab_type": "code",
        "outputId": "cca74e26-b76c-458a-b350-1db48c95b0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!java -version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.7\" 2020-04-14\n",
            "OpenJDK Runtime Environment (build 11.0.7+10-post-Ubuntu-2ubuntu218.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.7+10-post-Ubuntu-2ubuntu218.04, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdZCpO__faK2",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2 Update alternatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB_QF1Fcelk3",
        "colab_type": "text"
      },
      "source": [
        "If the java -version is not Java 8 version, you can use the following steps to install it and configure it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u0GMNLtxNa8",
        "colab_type": "code",
        "outputId": "e10f0eb9-48a0-4ebe-affd-1969fa5bce8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKDfuHN3fCV9",
        "colab_type": "text"
      },
      "source": [
        "Actually, Colab already had Java 8 installed. You can use the following code to choose the alternaives:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXgt5OyQyRtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !java -version\n",
        "# !sudo update-alternatives --config java\n",
        "# !java -version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrxc47QdlTw0",
        "colab_type": "text"
      },
      "source": [
        "### 2.Pysaprk Installation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COQWfiudicDj",
        "colab_type": "code",
        "outputId": "f616ebb2-07af-451a-d989-d23e5c7343e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 50kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 48.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=0e5ed66f95e6e7d33d7b8b3851ca616087462a0a8968bc3e8545a6f923871463\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCU2CErGgN_P",
        "colab_type": "text"
      },
      "source": [
        "### **3.Data Load**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03uJPkbtuTd_",
        "colab_type": "text"
      },
      "source": [
        "#### 3.1Mount your Google Drive to Collaboratory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtnMWUjZtm4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjAb7JDLuWvR",
        "colab_type": "text"
      },
      "source": [
        "Now you will see your Google Drive files in the left pane (file explorer). Right click on the file that you need to import and select copy path. Then import as usual in pandas, using this copied path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1g6gLRRgZrI",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2 Set the data path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z4WMH-ZuWpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'gdrive/My Drive/Colab_data/Advertising.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7XpVmn9ldnn",
        "colab_type": "text"
      },
      "source": [
        "### 4.SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "danEa1h6WeRO"
      },
      "source": [
        "#### 4.1 import and creating SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hmmryPW3WhKQ",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark create RDD example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9gTkgq_XHS0",
        "colab_type": "text"
      },
      "source": [
        "#### 4.2.Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "16Zs_z3GXj37",
        "colab": {}
      },
      "source": [
        "df = spark.read.csv(path=path,\n",
        "                    sep=',',encoding='UTF-8',comment=None,\n",
        "                    header=True,inferSchema=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH0XFDsnrXpt",
        "colab_type": "text"
      },
      "source": [
        "### 5.Data Exploration "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "97MSKeHOn976"
      },
      "source": [
        "#### 5.1 data show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGHjEx_yixDx",
        "colab_type": "code",
        "outputId": "de0067ba-cc4f-4018-aec8-bb60e6152489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "df.show(5,True)\n",
        "df.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+---------+-----+\n",
            "|   TV|Radio|Newspaper|Sales|\n",
            "+-----+-----+---------+-----+\n",
            "|230.1| 37.8|     69.2| 22.1|\n",
            "| 44.5| 39.3|     45.1| 10.4|\n",
            "| 17.2| 45.9|     69.3|  9.3|\n",
            "|151.5| 41.3|     58.5| 18.5|\n",
            "|180.8| 10.8|     58.4| 12.9|\n",
            "+-----+-----+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- TV: double (nullable = true)\n",
            " |-- Radio: double (nullable = true)\n",
            " |-- Newspaper: double (nullable = true)\n",
            " |-- Sales: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEBktg2prgp3",
        "colab_type": "text"
      },
      "source": [
        "#### 5.2 data columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9JomkVUrmLo",
        "colab_type": "code",
        "outputId": "4c3c38be-3759-4e9f-aec0-e36184a2e509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TV', 'Radio', 'Newspaper', 'Sales']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGhyiiuGYUgf",
        "colab_type": "code",
        "outputId": "f99a5b1a-f79c-4aab-d74a-1ef3d8cb9a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------------+------------------+------------------+------------------+\n",
            "|summary|               TV|             Radio|         Newspaper|             Sales|\n",
            "+-------+-----------------+------------------+------------------+------------------+\n",
            "|  count|              200|               200|               200|               200|\n",
            "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
            "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
            "|    min|              0.7|               0.0|               0.3|               1.6|\n",
            "|    max|            296.4|              49.6|             114.0|              27.0|\n",
            "+-------+-----------------+------------------+------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRf5XkC6YWAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "# I provide two ways to build the features and labels\n",
        "\n",
        "# method 1 (good for small feature):\n",
        "#def transData(row):\n",
        "#    return Row(label=row[\"Sales\"],\n",
        "#               features=Vectors.dense([row[\"TV\"],\n",
        "#                                       row[\"Radio\"],\n",
        "#                                       row[\"Newspaper\"]]))\n",
        "\n",
        "# Method 2 (good for large features):\n",
        "def transData(data):\n",
        "    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['features','label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GihpyEHYfWZ",
        "colab_type": "code",
        "outputId": "b40af5ee-a68c-4a7d-8215-2ed38b5bbb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "transformed= transData(df)\n",
        "transformed.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[230.1,37.8,69.2]| 22.1|\n",
            "| [44.5,39.3,45.1]| 10.4|\n",
            "| [17.2,45.9,69.3]|  9.3|\n",
            "|[151.5,41.3,58.5]| 18.5|\n",
            "|[180.8,10.8,58.4]| 12.9|\n",
            "+-----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua31BX_0YuLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):\n",
        "\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "    from pyspark.sql.functions import col\n",
        "\n",
        "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
        "                 for c in categoricalCols ]\n",
        "\n",
        "    # default setting: dropLast=True\n",
        "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
        "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
        "                 for indexer in indexers ]\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
        "                                + continuousCols, outputCol=\"features\")\n",
        "\n",
        "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "\n",
        "    model=pipeline.fit(df)\n",
        "    data = model.transform(df)\n",
        "\n",
        "    data = data.withColumn('label',col(labelCol))\n",
        "\n",
        "    if indexCol:\n",
        "        return data.select(indexCol,'features','label')\n",
        "    else:\n",
        "        return data.select('features','label')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p6toD4gEhoeT",
        "colab": {}
      },
      "source": [
        "def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol,dropLast=False):\n",
        "\n",
        "    '''\n",
        "    Get dummy variables and concat with continuous variables for ml modeling.\n",
        "    :param df: the dataframe\n",
        "    :param categoricalCols: the name list of the categorical data\n",
        "    :param continuousCols:  the name list of the numerical data\n",
        "    :param labelCol:  the name of label column\n",
        "    :param dropLast:  the flag of drop last column         \n",
        "    :return: feature matrix\n",
        "\n",
        "    :author: Wenqiang Feng\n",
        "    :email:  von198@gmail.com\n",
        "    '''\n",
        "\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "    from pyspark.sql.functions import col\n",
        "\n",
        "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
        "                 for c in categoricalCols ]\n",
        "\n",
        "    # default setting: dropLast=True\n",
        "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
        "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()),dropLast=dropLast)\n",
        "                 for indexer in indexers ]\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
        "                                + continuousCols, outputCol=\"features\")\n",
        "\n",
        "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "\n",
        "    model=pipeline.fit(df)\n",
        "    data = model.transform(df)\n",
        "\n",
        "    if indexCol and labelCol:\n",
        "        # for supervised learning\n",
        "        data = data.withColumn('label',col(labelCol))\n",
        "        return data.select(indexCol,'features','label')\n",
        "    elif not indexCol and labelCol:\n",
        "        # for supervised learning\n",
        "        data = data.withColumn('label',col(labelCol))\n",
        "        return data.select('features','label') \n",
        "    elif indexCol and not labelCol:\n",
        "        # for unsupervised learning\n",
        "        return data.select(indexCol,'features')\n",
        "    elif not indexCol and not labelCol:\n",
        "        # for unsupervised learning\n",
        "        return data.select('features')      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cf9n3fUYwZc",
        "colab_type": "code",
        "outputId": "c422fb0a-adb8-46f1-e274-c27adc2c9b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "indexCol = []\n",
        "categoricalCols = []\n",
        "continuousCols = df.columns[:-1]\n",
        "labelCol = df.columns[-1]\n",
        "print(continuousCols)\n",
        "print(labelCol)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['TV', 'Radio', 'Newspaper']\n",
            "Sales\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4T-qDE7ZI3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat = get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ntTOSBZxA1",
        "colab_type": "code",
        "outputId": "231d1d52-8202-4a04-bfd3-4ffd12f60eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "mat.show(4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[230.1,37.8,69.2]| 22.1|\n",
            "| [44.5,39.3,45.1]| 10.4|\n",
            "| [17.2,45.9,69.3]|  9.3|\n",
            "|[151.5,41.3,58.5]| 18.5|\n",
            "+-----------------+-----+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V33-cEQ0o5QZ",
        "colab_type": "text"
      },
      "source": [
        "### 4.Copyright notice and license info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_m92fnwm0la",
        "colab_type": "text"
      },
      "source": [
        "The copyright belongs to Wenqiang Feng. This document is licensed according to both [**MIT License**](https://github.com/runawayhorse001/LearningApacheSpark/blob/master/LICENSE) and [C**reative Commons Attribution-NonCommercial 2.0 Generic (CC BY-NC 2.0) License**](https://creativecommons.org/licenses/by-nc/2.0/legalcode). **Please give the corresponding credits to the author for his hard  work.**"
      ]
    }
  ]
}